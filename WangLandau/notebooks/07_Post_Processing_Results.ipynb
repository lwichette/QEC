{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpmath as mpmath\n",
    "import mpmath as mp\n",
    "mp.mp.dps = 30 #higher precision\n",
    "from post_processing import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pickle(\n",
    "    df, boundary_type, intervals, iterations,\n",
    "    overlap, walkers, alpha, beta, exchange, probabilities\n",
    "    ):\n",
    "\n",
    "    path = f\"../results_curves/{boundary_type}/X_{X}_Y_{Y}/prob_{probabilities:.6f}/free_energies_intervals_{intervals}_iterations_{iterations}_overlap_{overlap:.6f}_walkers_{walkers}_alpha_{alpha:.6f}_beta_{beta:.10f}_exchange_offset_{exchange}.pickle\"\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print(f\"File {path} already exists, checking duplicates and update dataframe\")\n",
    "        df_orig = pd.read_pickle(path)\n",
    "\n",
    "        df_combined = pd.concat([df_orig, df])\n",
    "\n",
    "        df_result = df_combined.drop_duplicates(subset=['histogram_seed', 'error'], keep='first')\n",
    "\n",
    "        df_result.to_pickle(path)\n",
    "    else:\n",
    "        print(f\"File {path} does not exist, write to disk\")\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_log_g(row):\n",
    "    log_g_list = row[\"log_g\"]\n",
    "    X = row[\"X\"]\n",
    "    Y = row[\"Y\"]\n",
    "\n",
    "    offset = log_sum_exp(log_g_list)\n",
    "\n",
    "    rescaled_log_g_list = [\n",
    "        res + mp.log(2)*X*Y - offset for res in log_g_list\n",
    "    ]\n",
    "\n",
    "    return rescaled_log_g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_post_processing(\n",
    "    probabilities, X, Y, boundary_type, intervals,\n",
    "    iterations, overlap, walkers, alpha, beta, exchange,\n",
    "    errors = {\"I\", \"X\", \"Y\", \"Z\"}, low_temp=1e-20, high_temp=1e20\n",
    "    ):\n",
    "\n",
    "        batch_results = []\n",
    "\n",
    "        for error in [\"I\", \"X\", \"Y\", \"Z\"]:\n",
    "            filename = f\"../results/{boundary_type}/prob_{probabilities:.6f}/X_{X}_Y_{Y}/error_class_{error}/StitchedHistogram_intervals_{intervals}_iterations_{iterations}_overlap_{overlap:.6f}_walkers_{walkers}_alpha_{alpha:.6f}_beta_{beta:.10f}_exchange_offset{exchange}.txt\"\n",
    "\n",
    "            data = read_results_file(filename)\n",
    "            if data:\n",
    "                process_data(data, batch_results, probabilities, X, Y, error)\n",
    "\n",
    "        df = pd.DataFrame(batch_results)\n",
    "\n",
    "        # Filter based on errors\n",
    "        df_filtered = df.groupby('histogram_seed').filter(\n",
    "            lambda x: set(x['error']) == errors and len(x) == len(errors)\n",
    "        )\n",
    "\n",
    "        df_filtered['rescaled_log_g'] = df_filtered.apply(rescale_log_g, axis=1)\n",
    "\n",
    "        df_sorted = df_filtered.sort_values(by=[\"histogram_seed\", \"error\"])\n",
    "\n",
    "        nish_temp = 1/(mp.log((1-probabilities)/probabilities)/2)\n",
    "\n",
    "        df_sorted[f\"free_energy_low_temp\"] = df_sorted.apply(lambda row: free_energy(row['E'], row['rescaled_log_g'], low_temp)/(-low_temp), axis=1)\n",
    "        df_sorted[f\"free_energy_nish_temp\"] = df_sorted.apply(lambda row: free_energy(row['E'], row['rescaled_log_g'], nish_temp)/(-nish_temp), axis=1)\n",
    "        df_sorted[f\"free_energy_high_temp\"] = df_sorted.apply(lambda row: free_energy(row['E'], row['rescaled_log_g'], high_temp)/(-high_temp), axis=1)\n",
    "\n",
    "        write_to_pickle(\n",
    "            df_sorted, boundary_type, intervals, iterations,\n",
    "            overlap, walkers, alpha, beta, exchange, probabilities\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_type = \"periodic\"\n",
    "intervals = 10\n",
    "iterations = 1000\n",
    "overlap = 0.25\n",
    "walkers = 8\n",
    "alpha = 0.8\n",
    "beta = 1e-8\n",
    "exchange = 20\n",
    "\n",
    "probabilities = [0.1, 0.11, 0.12, 0.13]\n",
    "X = 6\n",
    "Y = 6\n",
    "errors = [\"I\", \"X\", \"Y\", \"Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../results_curves/periodic/X_6_Y_6/prob_0.100000/free_energies_intervals_10_iterations_1000_overlap_0.250000_walkers_8_alpha_0.800000_beta_0.0000000100_exchange_offset_20.pickle does not exist, write to disk\n",
      "File ../results_curves/periodic/X_6_Y_6/prob_0.110000/free_energies_intervals_10_iterations_1000_overlap_0.250000_walkers_8_alpha_0.800000_beta_0.0000000100_exchange_offset_20.pickle does not exist, write to disk\n",
      "File ../results_curves/periodic/X_6_Y_6/prob_0.120000/free_energies_intervals_10_iterations_1000_overlap_0.250000_walkers_8_alpha_0.800000_beta_0.0000000100_exchange_offset_20.pickle does not exist, write to disk\n",
      "File ../results_curves/periodic/X_6_Y_6/prob_0.130000/free_energies_intervals_10_iterations_1000_overlap_0.250000_walkers_8_alpha_0.800000_beta_0.0000000100_exchange_offset_20.pickle does not exist, write to disk\n"
     ]
    }
   ],
   "source": [
    "for p in probabilities:\n",
    "\n",
    "    perform_post_processing(\n",
    "        p, X, Y, boundary_type, intervals,\n",
    "        iterations, overlap, walkers, alpha, beta, exchange\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "og",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
