{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotDensity import *\n",
    "import mpmath as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(to_sum):\n",
    "    maxval = max(to_sum)\n",
    "    exp_sum = 0\n",
    "    for value in to_sum:\n",
    "        exp_sum += mp.exp(value-maxval)\n",
    "    res = maxval + mp.log(exp_sum)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is set to e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = (4,4)\n",
    "\n",
    "\"\"\"Incoming data to get handled by new result handling function\"\"\"\n",
    "interval_data = [\n",
    "  627.1095947266,\n",
    "  628.8754638672,\n",
    "  630.9088623047,\n",
    "  632.5491699219,\n",
    "  633.5110107422,\n",
    "  404.7702880859,\n",
    "  406.3506591797,\n",
    "  407.3104492188,\n",
    "  407.8216796875,\n",
    "  407.8045410156,\n",
    "  404.0828857422,\n",
    "  405.1276611328,\n",
    "  405.6312011719,\n",
    "  405.6431152344,\n",
    "  405.1499023438,\n",
    "  401.4141113281,\n",
    "  401.9133789062,\n",
    "  401.9149902344,\n",
    "  401.4306152344,\n",
    "  400.5290527344,\n",
    "  402.1429199219,\n",
    "  402.1175537109,\n",
    "  401.6156250000,\n",
    "  400.6624267578,\n",
    "  399.0767089844,\n",
    "  613.2126708984,\n",
    "  612.2446777344,\n",
    "  610.6416259766,\n",
    "  608.6352050781,\n",
    "  606.9015625000\n",
    "]\n",
    "\n",
    "\"\"\"data after applying min rescaling in new result handling function\"\"\"\n",
    "min_rescaled_data = [\n",
    "  0.0000000000,\n",
    "  1.7658691406,\n",
    "  3.7992675781,\n",
    "  5.4395751953,\n",
    "  6.4014160156,\n",
    "  0.0000000000,\n",
    "  1.5803710938,\n",
    "  2.5401611328,\n",
    "  3.0513916016,\n",
    "  3.0342529297,\n",
    "  0.0000000000,\n",
    "  1.0447753906,\n",
    "  1.5483154297,\n",
    "  1.5602294922,\n",
    "  1.0670166016,\n",
    "  0.8850585938,\n",
    "  1.3843261719,\n",
    "  1.3859375000,\n",
    "  0.9015625000,\n",
    "  0.0000000000,\n",
    "  3.0662109375,\n",
    "  3.0408447266,\n",
    "  2.5389160156,\n",
    "  1.5857177734,\n",
    "  0.0000000000,\n",
    "  6.3111083984,\n",
    "  5.3431152344,\n",
    "  3.7400634766,\n",
    "  1.7336425781,\n",
    "  0.0000000000\n",
    "]\n",
    "\n",
    "\"\"\"data after rescaling for stitching intervals\"\"\"\n",
    "stitched_data = [\n",
    "  0.0000000000,\n",
    "  1.7658691406,\n",
    "  3.7992675781,\n",
    "  5.4395751953,\n",
    "  6.4014160156,\n",
    "  3.8592041016,\n",
    "  5.4395751953,\n",
    "  6.3993652344,\n",
    "  6.9105957031,\n",
    "  6.8934570313,\n",
    "  5.3545898438,\n",
    "  6.3993652344,\n",
    "  6.9029052734,\n",
    "  6.9148193359,\n",
    "  6.4216064453,\n",
    "  6.3993652344,\n",
    "  6.8986328125,\n",
    "  6.9002441406,\n",
    "  6.4158691406,\n",
    "  5.5143066406,\n",
    "  6.9256103516,\n",
    "  6.9002441406,\n",
    "  6.3983154297,\n",
    "  5.4451171875,\n",
    "  3.8593994141,\n",
    "  6.3983154297,\n",
    "  5.4303222656,\n",
    "  3.8272705078,\n",
    "  1.8208496094,\n",
    "  0.0872070313\n",
    "]\n",
    "\n",
    "cut_data = {\n",
    "  \"-22\": 0.0000000000,\n",
    "  \"-18\": 1.7658691406,\n",
    "  \"-14\": 3.7992675781,\n",
    "  \"-10\": 5.4395751953,\n",
    "  \"-6\": 6.3993652344,\n",
    "  \"-2\": 6.8986328125,\n",
    "  \"2\": 6.9002441406,\n",
    "  \"6\": 6.3983154297,\n",
    "  \"10\": 5.4303222656,\n",
    "  \"14\": 3.8272705078,\n",
    "  \"18\": 1.8208496094,\n",
    "  \"22\": 0.0872070312\n",
    "}\n",
    "\n",
    "normalized_data = {\n",
    "  \"-22\": 2.8611055117,\n",
    "  \"-18\": 4.6269746524,\n",
    "  \"-14\": 6.6603730899,\n",
    "  \"-10\": 8.3006807071,\n",
    "  \"-6\": 9.2604707461,\n",
    "  \"-2\": 9.7597383242,\n",
    "  \"2\": 9.7613496524,\n",
    "  \"6\": 9.2594209414,\n",
    "  \"10\": 8.2914277774,\n",
    "  \"14\": 6.6883760196,\n",
    "  \"18\": 4.6819551211,\n",
    "  \"22\": 2.9483125430\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result_handling_out = read_data_from_file(\"../results/test/test_intervals6.txt\")\n",
    "\n",
    "\"\"\"Reducing to single walker resutl per interval\"\"\"\n",
    "walker_results = average_matching_keys(old_result_handling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result_handling_out_concatenated = [list(d.values()) for d in walker_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION INPUT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs((np.concatenate(old_result_handling_out_concatenated)) - np.array(interval_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"minimum rescaling of results per interval\"\"\"\n",
    "old_result_handling_min_rescaled =  get_renormalized_log_g_values(walker_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION MIN RESCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0003353700938078e-10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs(np.concatenate(old_result_handling_min_rescaled[1])- np.array(min_rescaled_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker_results = old_result_handling_out\n",
    "\n",
    "\"\"\"normalize the walker results by min value for log results\"\"\"\n",
    "walker_results = get_renormalized_log_g_values_as_dict_list(walker_results)\n",
    "\n",
    "\"\"\"averages over walker results per intervals\"\"\"\n",
    "walker_results = average_matching_keys(walker_results)\n",
    "\n",
    "results_x = []\n",
    "results_y = []\n",
    "for result in walker_results:\n",
    "    results_y.append(np.array(list(result.values())))\n",
    "    results_x.append(np.array(list(result.keys())))\n",
    "\n",
    "derivatives_wrt_e = get_derivative_wrt_e(walker_results)\n",
    "minimum_deviation_energies = find_lowest_inverse_temp_deviation(derivatives_wrt_e)\n",
    "rescale_results_for_concatenation(results_x, results_y, minimum_deviation_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Store concatenate interval results\"\"\"\n",
    "concatenated_keys = np.concatenate(results_x)\n",
    "concatenated_values = np.concatenate(results_y)\n",
    "list_of_concat_rescale_dicts = []\n",
    "for keys, values in zip(results_x, results_y):\n",
    "    # Combine keys and values into a dictionary\n",
    "    dict_from_arrays = {k: v for k, v in zip(keys, values)}\n",
    "    list_of_concat_rescale_dicts.append(dict_from_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION CONCATENATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0010038070950031e-10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs(concatenated_values - np.array(stitched_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cut overlapping parts\"\"\"\n",
    "x_max = -1 -2*X*Y\n",
    "unique_x = []\n",
    "unique_y = []\n",
    "\n",
    "sorted_dict_list = [dict(sorted(d.items())) for d in list_of_concat_rescale_dicts]\n",
    "\n",
    "for dictionary in sorted_dict_list:\n",
    "    for key, value in dictionary.items():\n",
    "        if key > x_max: #avoid double counting\n",
    "            x_max = key\n",
    "            unique_x.append(key)\n",
    "            unique_y.append(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION CUT OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.11022302e-14,  5.72875081e-14, -5.32907052e-15,\n",
       "        2.05078120e-03,  1.19628906e-02, -6.78710940e-03,  2.32910157e-02,\n",
       "        8.39843751e-02,  3.21289064e-02,  9.99873517e-11,  1.99998421e-10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(unique_y) - np.array(list(cut_data.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IMPLIES PROBLEM WITH NAIVE CUT OF OVERLAP IN PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSUMING NOW INPUT FOR LOG SUM EXP RESCALING WHICH GOES INTO C CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data_input = np.array(list(cut_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mpf('2.8611055117440856'), mpf('4.6269746523440851'), mpf('6.6603730898440858'), mpf('8.3006807070440853'), mpf('9.2604707461440849'), mpf('9.7597383242440845'), mpf('9.7613496523440855'), mpf('9.2594209414440858'), mpf('8.2914277773440848'), mpf('6.6883760195440853'), mpf('4.6819551211440853'), mpf('2.9483125429440857')]\n"
     ]
    }
   ],
   "source": [
    "offset = log_sum_exp(cut_data_input)\n",
    "rescaled_y = [res + mp.log(2)*16 - offset for res in cut_data_input]\n",
    "print(rescaled_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION LOG SUM EXP RESCALING FOR SAME INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('5.5915272412221384e-11')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs(np.array(rescaled_y) - np.array(list(normalized_data.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE WAY OF CUTTING THE OVERLAP ANALOGOUSLY TO C CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_overlapping_histogram_parts(interval_data, stitching_keys):\n",
    "    for i in range(len(stitching_keys)):\n",
    "        stitching_energy_of_interval_i = stitching_keys[i]\n",
    "\n",
    "        # Modify the i-th interval\n",
    "        current_interval = interval_data[i]\n",
    "        # Keep only keys <= stitching_energy_of_interval_i\n",
    "        current_interval = {k: v for k, v in current_interval.items() if k <= stitching_energy_of_interval_i}\n",
    "\n",
    "        # Modify the (i+1)-th interval if following interval is still in bounds\n",
    "        if i + 1 < len(interval_data):\n",
    "            next_interval = interval_data[i + 1]\n",
    "            # Keep only keys > stitching_energy_of_interval_i\n",
    "            next_interval = {k: v for k, v in next_interval.items() if k > stitching_energy_of_interval_i}\n",
    "\n",
    "        # Update the intervals in the original list\n",
    "        interval_data[i] = current_interval\n",
    "        if i + 1 < len(interval_data):\n",
    "            interval_data[i + 1] = next_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_overlapping_histogram_parts(list_of_concat_rescale_dicts, minimum_deviation_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of dictionaries into a single list of values\n",
    "cut_values = [value for d in list_of_concat_rescale_dicts for value in d.values()]\n",
    "\n",
    "# Convert the list of values into a NumPy array\n",
    "cut_values_array = np.array(cut_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVIATION OF CUT RESULTS NEW IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0010038070950031e-10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs(cut_values_array-np.array(list(cut_data.values()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
